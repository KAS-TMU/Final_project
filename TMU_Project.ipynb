{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbformat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,recall_score,roc_auc_score,f1_score,roc_curve, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%pip install xgboost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/ornif/Downloads/archive (1)/application_record.csv', encoding= 'utf-8')\n",
    "record = pd.read_csv('C:/Users/ornif/Downloads/archive (1)/credit_record.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of datapoints for application records: {}\".format(len(data)))\n",
    "print(\"Number of unique clients in dataset: {}\".format(len(data.ID.unique())))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of datapoints for credit records: {}\".format(len(record)))\n",
    "print(\"Number of unique clients in dataset: {}\".format(len(record.ID.unique())))\n",
    "record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique clients and rows are not equal,which means there are duplicates.\n",
    "\n",
    "# Checking to see how many records match in two datasets\n",
    "\n",
    "len(set(record['ID']).intersection(set(data['ID']))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_missing_1 = msno.matrix(data)\n",
    "\n",
    "plt_missing_1.set_title(\"Missing Data for application records dataset\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_missing_2 = msno.matrix(record)\n",
    "\n",
    "plt_missing_2.set_title(\"Missing Data for credit records dataset\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values\n",
    "\n",
    "unique_counts = pd.DataFrame.from_records([(col, data[col].nunique()) for col in data.columns],\n",
    "                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])\n",
    "unique_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = pd.DataFrame.from_records([(col, record[col].nunique()) for col in record.columns],\n",
    "                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])\n",
    "unique_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\",font_scale=.7,rc={\"grid.linewidth\": 0.1,'patch.linewidth': 0.0,\n",
    "    \"axes.grid\":True,\n",
    "    \"grid.linestyle\": \"-\",\n",
    "    \"axes.titlesize\" : 13,                                       \n",
    "    \"figure.autolayout\":True})\n",
    "                \n",
    "palette_1 = ['#FF5E5B','#EC9B9A','#00CECB','#80DE99','#C0E680','#FFED66']\n",
    "\n",
    "sns.set_palette(sns.color_palette(sns.color_palette(palette_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "cols_to_plot = [\"CNT_CHILDREN\",\"AMT_INCOME_TOTAL\",\"DAYS_BIRTH\",\"DAYS_EMPLOYED\"]\n",
    "data[cols_to_plot].hist(edgecolor='black', linewidth=1.2)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "\n",
    "g1=sns.countplot(y=data.NAME_INCOME_TYPE,linewidth=1.2, ax=axes[0])\n",
    "g1.set_title(\"Customer Distribution by Income Type\")\n",
    "g1.set_xlabel(\"Count\")\n",
    "\n",
    "g2=sns.countplot(y=data.NAME_FAMILY_STATUS,linewidth=1.2, ax=axes[1])\n",
    "g2.set_title(\"Customer Distribution by Family Status\")\n",
    "g2.set_xlabel(\"Count\")\n",
    "\n",
    "fig.set_size_inches(14,5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "\n",
    "g1= sns.countplot(y=data.NAME_HOUSING_TYPE,linewidth=1.2, ax=axes[0])\n",
    "g1.set_title(\"Customer Distribution by Housing Type\")\n",
    "g1.set_xlabel(\"Count\")\n",
    "g1.set_ylabel(\"Housing Type\")\n",
    "\n",
    "g2= sns.countplot(y=data.NAME_EDUCATION_TYPE, ax=axes[1])\n",
    "g2.set_title(\"Customer Distribution by Education\")\n",
    "g2.set_xlabel(\"Count\")\n",
    "g2.set_ylabel(\"Education Type\")\n",
    "\n",
    "fig.set_size_inches(14,5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3)\n",
    "\n",
    "g1= data['CODE_GENDER'].value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True, colors=[\"#76B5B3\",\"#EC9B9A\"],textprops = {'fontsize':12}, ax=axes[0])\n",
    "g1.set_title(\"Customer Distribution by Gender\")\n",
    "\n",
    "g2= data['FLAG_OWN_CAR'].value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True,colors=[\"#80DE99\",\"#00CECB\"],textprops = {'fontsize':12}, ax=axes[1])\n",
    "g2.set_title(\"Car Ownership\")\n",
    "\n",
    "g3= data['FLAG_OWN_REALTY'].value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True,colors=[\"#76B5B3\",\"#00CECB\"],textprops = {'fontsize':12}, ax=axes[2])\n",
    "g3.set_title(\"Realty Ownership\")\n",
    "\n",
    "fig.set_size_inches(14,5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates('ID', keep='last') #remove duplicate values and keep the last entry of the ID if its repeated.\n",
    "data.drop('OCCUPATION_TYPE', axis=1, inplace=True) #the occupation type has missing values, we dropped them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = data.columns[data.dtypes =='object'].tolist() #object columns in dataset\n",
    "\n",
    "unique_counts = pd.DataFrame.from_records([(col, data[object_columns][col].nunique()) for col in data[object_columns].columns],\n",
    "                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])\n",
    "\n",
    "unique_counts #unique counts for object columns\n",
    "\n",
    "# We have filtered the columns that have non numeric values to see if they are useful. We will convert them numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "\n",
    "data.rename(columns={\"CODE_GENDER\":\"Gender\",\"FLAG_OWN_CAR\":\"Own_Car\",\"FLAG_OWN_REALTY\":\"Own_Realty\",\n",
    "                     \"CNT_CHILDREN\":\"Children_Count\",\"AMT_INCOME_TOTAL\":\"Income\",\"NAME_EDUCATION_TYPE\":\"Education\",\n",
    "                     \"NAME_FAMILY_STATUS\":\"Family_Status\",\"NAME_HOUSING_TYPE\":\"Housing_Type\",\"DAYS_BIRTH\":\"Birthday\",\n",
    "                     \"DAYS_EMPLOYED\":\"Employment_Date\",\"FLAG_MOBIL\":\"Own_Mobile\",\"FLAG_WORK_PHONE\":\"Own_Work_Phone\",\n",
    "                     \"FLAG_PHONE\":\"Own_Phone\",\"FLAG_EMAIL\":\"Own_Email\",\"CNT_FAM_MEMBERS\":\"Family_Member_Count\",\n",
    "                    \"NAME_INCOME_TYPE\":\"Income_Type\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all users account open month\n",
    "\n",
    "open_month=pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "open_month=open_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "customer_data=pd.merge(data,open_month,how=\"left\",on=\"ID\") #merge to record data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categoric features into numeric\n",
    "\n",
    "customer_data[\"Gender\"] =  customer_data['Gender'].replace(['F','M'],[0,1])\n",
    "customer_data[\"Own_Car\"] = customer_data[\"Own_Car\"].replace([\"Y\",\"N\"],[1,0])\n",
    "customer_data[\"Own_Realty\"] = customer_data[\"Own_Realty\"].replace([\"Y\",\"N\"],[1,0])\n",
    "customer_data[\"Is_Working\"] = customer_data[\"Income_Type\"].replace([\"Working\",\"Commercial associate\",\"State servant\",\"Pensioner\",\"Student\"],[1,1,1,0,0])\n",
    "\n",
    "customer_data[\"In_Relationship\"] = customer_data[\"Family_Status\"].replace([\"Civil marriage\",\"Married\",\"Single / not married\",\n",
    "                                                                          \"Separated\",\"Widow\"],[1,1,0,0,0])\n",
    "\n",
    "housing_type = {'House / apartment' : 'House / apartment',\n",
    "                   'With parents': 'With parents',\n",
    "                    'Municipal apartment' : 'House / apartment',\n",
    "                    'Rented apartment': 'House / apartment',\n",
    "                    'Office apartment': 'House / apartment',\n",
    "                    'Co-op apartment': 'House / apartment'}\n",
    "\n",
    "customer_data[\"Housing_Type\"] = customer_data['Housing_Type'].map(housing_type)\n",
    "\n",
    "family_status = {'Single / not married':'Single',\n",
    "                     'Separated':'Single',\n",
    "                     'Widow':'Single',\n",
    "                     'Civil marriage':'Married',\n",
    "                    'Married':'Married'}\n",
    "\n",
    "customer_data[\"Family_Status\"] = customer_data[\"Family_Status\"].map(family_status)\n",
    "\n",
    "education_type = {'Secondary / secondary special':'secondary',\n",
    "                     'Lower secondary':'secondary',\n",
    "                     'Higher education':'Higher education',\n",
    "                     'Incomplete higher':'Higher education',\n",
    "                     'Academic degree':'Academic degree'}\n",
    "\n",
    "customer_data[\"Education\"] = customer_data[\"Education\"].map(education_type)\n",
    "\n",
    "income_type = {'Commercial associate':'Working',\n",
    "                  'State servant':'Working',\n",
    "                  'Working':'Working',\n",
    "                  'Pensioner':'Pensioner',\n",
    "                  'Student':'Student'}\n",
    "\n",
    "customer_data[\"Income_Type\"] = customer_data[\"Income_Type\"].map(income_type)\n",
    "\n",
    "customer_data[\"Household_Size\"] = customer_data[\"Children_Count\"] + customer_data[\"In_Relationship\"].apply(lambda x: 2 if x==1 else 1)\n",
    "\n",
    "customer_data[\"Age\"] = round((customer_data.Birthday/365)*-1)\n",
    "\n",
    "customer_data[\"Experience\"] = customer_data.Employment_Date/365\n",
    "customer_data['Experience']=customer_data['Experience'].apply(lambda v : int(v*-1) if v <0 else 0)\n",
    "\n",
    "customer_data=customer_data.drop(columns=['Employment_Date','Birthday','Children_Count'])\n",
    "\n",
    "customer_data= pd.get_dummies(customer_data, columns=['Income_Type', 'Education','Family_Status',\"Housing_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at numeric columns to see if there is anything that needs to be changed.\n",
    "\n",
    "other_numerical_cols = [\"Income\",\"Age\",\"Experience\",\"Household_Size\"]\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2, start_cell=\"bottom-left\",\n",
    "                   subplot_titles=(\"Income\", \"Age\", \"Experience\", \"Family Member Count\"))\n",
    "\n",
    "fig.add_trace(go.Box(x=customer_data.Income, name='Income',boxmean=True),row=1,col=1)\n",
    "fig.add_trace(go.Box(x=customer_data.Age, name='Age', boxmean=True), row=1, col=2)\n",
    "fig.add_trace(go.Box(x=customer_data.Experience, name='Experience', boxmean=True), row=2, col=1)\n",
    "fig.add_trace(go.Box(x=customer_data.Household_Size, name=\"Family Member Count\", boxmean=True),row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seen above, there are some outliers values in children count, family member count, income and employment rate columns\n",
    "\n",
    "# We need to remove these outliers to make sure they do not affect our model results.\n",
    "# We will now remove these outliers by using z scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_scores(df, cols):\n",
    "    for col in cols:\n",
    "        df[col+\"_z_score\"] = (df[col] - df[col].mean())/df[col].std()\n",
    "    return df\n",
    "\n",
    "df_2 = calculate_z_scores(df = customer_data, cols = [\"Income\",\"Experience\",\"Household_Size\"])\n",
    "\n",
    "#removing outliers\n",
    "filter_2 = df_2.Household_Size_z_score.abs() <= 3.5\n",
    "filter_3 = df_2.Experience_z_score.abs() <= 3.5\n",
    "filter_4 = df_2.Income_z_score.abs() <= 3.5\n",
    "\n",
    "customer_apps = df_2[filter_2 & filter_3 & filter_4]\n",
    "\n",
    "customer_apps.drop(columns= [\"Income_z_score\",\"Experience_z_score\",\"Household_Size_z_score\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_numerical_cols = [\"Income\",\"Age\",\"Experience\",\"Family_Member_Count\"]\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2, start_cell=\"bottom-left\",\n",
    "                   subplot_titles=(\"Income\", \"Age\", \"Experience\", \"Family Member Count\"))\n",
    "\n",
    "fig.add_trace(go.Box(x=customer_apps.Income, name='Income',boxmean=True),row=1,col=1)\n",
    "fig.add_trace(go.Box(x=customer_apps.Age, name='Age', boxmean=True), row=1, col=2)\n",
    "fig.add_trace(go.Box(x=customer_apps.Experience, name='Experience', boxmean=True), row=2, col=1)\n",
    "fig.add_trace(go.Box(x=customer_apps.Household_Size, name=\"Family Member Count\", boxmean=True),row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['dep_value'] = None\n",
    "record['dep_value'][record['STATUS'] =='2']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='3']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='4']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='5']='Yes' \n",
    "\n",
    "record_count=record.groupby('ID').count()\n",
    "record_count['dep_value'][record_count['dep_value'] > 0]='Yes' \n",
    "record_count['dep_value'][record_count['dep_value'] == 0]='No' \n",
    "record_count = record_count[['dep_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame to analyze length of time since initial approval of credit card\n",
    "\n",
    "# Shows number of past dues, paid off and no loan status.\n",
    "grouped = record.groupby('ID')\n",
    "\n",
    "pivot_tb = record.pivot(index = 'ID', columns = 'MONTHS_BALANCE', values = 'STATUS')\n",
    "pivot_tb['open_month'] = grouped['MONTHS_BALANCE'].min()\n",
    "pivot_tb['end_month'] = grouped['MONTHS_BALANCE'].max()\n",
    "pivot_tb['window'] = pivot_tb['end_month'] - pivot_tb['open_month']\n",
    "pivot_tb['window'] += 1 # Adding 1 since month starts at 0.\n",
    "\n",
    "#Counting number of past dues, paid offs and no loans.\n",
    "pivot_tb['paid_off'] = pivot_tb[pivot_tb.iloc[:,0:61] == 'C'].count(axis = 1)\n",
    "pivot_tb['pastdue_1-29'] = pivot_tb[pivot_tb.iloc[:,0:61] == '0'].count(axis = 1)\n",
    "pivot_tb['pastdue_30-59'] = pivot_tb[pivot_tb.iloc[:,0:61] == '1'].count(axis = 1)\n",
    "pivot_tb['pastdue_60-89'] = pivot_tb[pivot_tb.iloc[:,0:61] == '2'].count(axis = 1)\n",
    "pivot_tb['pastdue_90-119'] = pivot_tb[pivot_tb.iloc[:,0:61] == '3'].count(axis = 1)\n",
    "pivot_tb['pastdue_120-149'] = pivot_tb[pivot_tb.iloc[:,0:61] == '4'].count(axis = 1)\n",
    "pivot_tb['pastdue_over_150'] = pivot_tb[pivot_tb.iloc[:,0:61] == '5'].count(axis = 1)\n",
    "pivot_tb['no_loan'] = pivot_tb[pivot_tb.iloc[:,0:61] == 'X'].count(axis = 1)\n",
    "\n",
    "#Setting ID column to merge with app data.\n",
    "pivot_tb['ID'] = pivot_tb.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_tb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame()\n",
    "target['ID'] = pivot_tb.index\n",
    "target['paid_off'] = pivot_tb['paid_off'].values\n",
    "target['#_of_pastdues'] = pivot_tb['pastdue_1-29'].values+ pivot_tb['pastdue_30-59'].values + pivot_tb['pastdue_60-89'].values +pivot_tb['pastdue_90-119'].values+pivot_tb['pastdue_120-149'].values +pivot_tb['pastdue_over_150'].values\n",
    "target['no_loan'] = pivot_tb['no_loan'].values\n",
    "customer_apps_1 = customer_apps.merge(target, how = 'inner', on = 'ID')\n",
    "\n",
    "customer_apps_2=pd.merge(customer_apps_1,record_count,how='inner',on='ID')\n",
    "customer_apps_2['target']=customer_apps_2['dep_value']\n",
    "customer_apps_2.loc[customer_apps_2['target']=='Yes','target']=1\n",
    "customer_apps_2.loc[customer_apps_2['target']=='No','target']=0\n",
    "\n",
    "customer_apps_2.drop(columns=[\"dep_value\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15,15))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "corr = customer_apps_2.drop(columns=[\"Own_Mobile\"]).corr().round(1)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, annot=True, mask = mask, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_apps_2['target'].value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True, colors=['#FF5E5B', '#C0E680'],textprops = {'fontsize':7}).set_title(\"Target distribution\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\",font_scale=.7,rc={\"grid.linewidth\": 0.1,'patch.linewidth': 0.0,\n",
    "    \"axes.grid\":True,\n",
    "    \"grid.linestyle\": \"-\",\n",
    "    \"axes.titlesize\" : 13,                                       \n",
    "    'figure.figsize':(15,15)})\n",
    "                \n",
    "palette_1 = ['#FF5E5B','#EC9B9A','#00CECB','#80DE99','#C0E680','#FFED66']\n",
    "\n",
    "sns.set_palette(sns.color_palette(sns.color_palette(palette_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3)\n",
    "\n",
    "g1=sns.boxenplot(x='target', y='Income', data=customer_apps_2,palette=['#FF5E5B', '#C0E680'], ax=axes[0])\n",
    "g1.set_title(\"Income-Target\")\n",
    "g2=sns.boxenplot(x='target', y='Age', data=customer_apps_2,palette=['#FF5E5B', '#C0E680'], ax=axes[1])\n",
    "g2.set_title(\"Age-Target\")\n",
    "g3=sns.boxenplot(x='target', y='Experience', data=customer_apps_2,palette=['#FF5E5B', '#C0E680'], ax=axes[2])\n",
    "g3.set_title(\"Work Experience-Target\")\n",
    "\n",
    "fig.set_size_inches(14,5)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=customer_apps_2, x='Income', hue=\"Is_Working\", col='target', kind=\"kde\", height=4, facet_kws={'sharey': False, 'sharex': False},palette=['#C70039','#80DE99'])\n",
    "sns.displot(data=customer_apps_2, x='Age', hue=\"Is_Working\", col='target', kind=\"kde\", height=4, facet_kws={'sharey': False, 'sharex': False},palette=['#C70039','#80DE99'])\n",
    "sns.displot(data=customer_apps_2, x='Experience', hue=\"Is_Working\", col='target', kind=\"kde\", height=4, facet_kws={'sharey': False, 'sharex': False},palette=['#C70039','#80DE99'])\n",
    "sns.displot(data=customer_apps_2, x='begin_month', hue=\"Is_Working\", col='target', kind=\"kde\", height=4, facet_kws={'sharey': False, 'sharex': False},palette=['#C70039','#80DE99'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=customer_apps_2, x='no_loan', hue=\"Is_Working\", col='target', kind=\"kde\", height=4, facet_kws={'sharey': False, 'sharex': False},palette=['#C70039','#80DE99'])\n",
    "sns.displot(data=customer_apps_2, x='#_of_pastdues', hue=\"Is_Working\", col='target', kind=\"kde\", height=4, facet_kws={'sharey': False, 'sharex': False},palette=['#C70039','#80DE99'])\n",
    "sns.displot(data=customer_apps_2, x='paid_off', hue=\"Is_Working\", col='target', kind=\"kde\", height=4, facet_kws={'sharey': False, 'sharex': False},palette=['#C70039','#80DE99'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_apps_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = customer_apps_2.iloc[:,1:-1]\n",
    "y = customer_apps_2[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting data into train-test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100, test_size=0.4)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')\n",
    "X_balance,Y_balance = SMOTE().fit_resample(X_train,y_train)\n",
    "X_balance = pd.DataFrame(X_balance, columns = X_train.columns)\n",
    "Y_balance = pd.DataFrame(Y_balance, columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data size check\n",
    "len(X_balance) == len(X_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information value\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    \n",
    "    lst = []\n",
    "\n",
    "    df[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "\n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print('IV = ', data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "\n",
    "    return iv, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df = X_balance.copy()\n",
    "iv_df[\"target\"] = y_train\n",
    "\n",
    "features = iv_df.columns[:-1].tolist()\n",
    "\n",
    "iv_list = []\n",
    "for feature in features:\n",
    "    iv, data = calc_iv(iv_df, feature, 'target')\n",
    "    iv_list.append(round(iv,4))\n",
    "\n",
    "woe_df = pd.DataFrame(np.column_stack([features, iv_list]), \n",
    "                      columns=['Feature', 'iv'])\n",
    "woe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE SCALING\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_balance)\n",
    "\n",
    "X_train = pd.DataFrame(scaler.transform(X_balance), columns=[X_balance.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, n_features_to_select=15)\n",
    "fit = rfe.fit(X_train, Y_balance)\n",
    "rfe_features = pd.DataFrame({\"Feature\":features,\n",
    "              \"Support_LogisticRegression\":fit.support_,\n",
    "              \"Feature_Rank_logisticRegression\":fit.ranking_})\n",
    "\n",
    "rfe_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=10)\n",
    "model.fit(X_balance, Y_balance)\n",
    "feature_importances = pd.DataFrame({\"Feature\":features,\n",
    "              \"Feature_Importance_ExtratreeClassifier\":model.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.merge(woe_df, feature_importances, on=[\"Feature\"])\n",
    "feature_selection_df = pd.merge(df1, rfe_features, on=[\"Feature\"])\n",
    "feature_selection_df.sort_values(by=\"iv\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"begin_month\",\"Income\",\"Experience\",\"In_Relationship\",\n",
    "                     \"Education_Higher education\",\"Education_secondary\",\"Own_Realty\",\n",
    "                     \"Family_Status_Single\",\"Family_Member_Count\",\"Is_Working\",\n",
    "                     \"Own_Car\",\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"KNeighbors\": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=250, max_depth=12, min_samples_leaf=16),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        max_depth=12,\n",
    "        n_estimators=250,\n",
    "        min_child_weight=8,\n",
    "        subsample=0.8,\n",
    "        learning_rate=0.02,\n",
    "        seed=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "result_dfs = []  # List to store individual DataFrames\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_balance[selected_features], Y_balance)\n",
    "    y_predict = classifier.predict(X_test[selected_features])\n",
    "\n",
    "    yproba = classifier.predict_proba(X_test[selected_features])[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, yproba)\n",
    "    auc = roc_auc_score(y_test, yproba)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        {\n",
    "            \"classifiers\": key,\n",
    "            \"accuracy\": accuracy_score(y_test, y_predict),\n",
    "            \"precision\": precision_score(y_test, y_predict, average=\"weighted\"),\n",
    "            \"recall\": recall_score(y_test, y_predict, average=\"weighted\"),\n",
    "            \"f1_score\": f1_score(y_test, y_predict, average=\"weighted\"),\n",
    "            \"fpr\": [fpr],\n",
    "            \"tpr\": [tpr],\n",
    "            \"auc\": [auc],\n",
    "        }\n",
    "    )\n",
    "    result_dfs.append(result_df)\n",
    "\n",
    "result_table = pd.concat(result_dfs, ignore_index=True)\n",
    "result_table.set_index(\"classifiers\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,10))\n",
    "\n",
    "for ax, cls in zip(axes.flatten(), classifiers.values()):\n",
    "\n",
    "  disp = ConfusionMatrixDisplay.from_predictions(y_test, cls.predict(X_test[selected_features]), \n",
    "                                                cmap=plt.cm.Blues,\n",
    "                                                ax=ax)\n",
    "\n",
    "  disp.ax_.set_title(type(cls).__name__)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.iloc[:,:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
